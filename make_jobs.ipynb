{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to use the array job feature of the cluster to run multiple experiments in parallel\n",
    "# in the job file we'd like the array index to influence the configuration of the experiment\n",
    "\n",
    "\n",
    "job_template = \"\"\"#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=staging\n",
    "#SBATCH --gpus=0\n",
    "#SBATCH --job-name={job_name}\n",
    "#SBATCH --ntasks={n_tasks}\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --time=2:00:00\n",
    "#SBATCH --mem=7000M\n",
    "#SBATCH --output=../outputs/{job_name}_%A_%a.out\n",
    "\n",
    "module purge\n",
    "module load 2022\n",
    "module load Anaconda3/2022.05\n",
    "\n",
    "# Activate your environment\n",
    "source activate EVOMAN\n",
    "# Change to the directory where your code is located\n",
    "cd ../evoman_framework\n",
    "# Run your code\n",
    "srun -n {n_tasks} python -u run_optim.py {config_str} --enemy_sets $SLURM_ARRAY_TASK_ID --start_new --run_evolution --n_runs 1 --name {job_name}\"\"\"\n",
    "\n",
    "n_tasks = 30\n",
    "\n",
    "# Generate job files like the above for each of the following configurations\n",
    "# and save them in ../jobs/{job_name}.job\n",
    "# The job files will be used to run the experiments on the cluster\n",
    "\n",
    "\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--randomini',              type=str, default='no',         help='usage: --randomini yes/no')\n",
    "    parser.add_argument('--multi_ini',              type=bool, default=False,       help='usage: --multi_ini True/False')\n",
    "    parser.add_argument('--normalization_method',   type=str, default='default',    help='usage: --normalization_method default/domain_specific/around_0')\n",
    "    parser.add_argument('--fitness_method',         type=str, default='rank',    help='usage: --fitness_method default/balanced/rank')\n",
    "    parser.add_argument('--pick_parent_method',     type=str, default='multinomial', help='usage: --pick_parent_method multinomial/tournament/greedy')\n",
    "    parser.add_argument('--survivor_method',        type=str, default='multinomial', help='usage: --survivor_method greedy/multinomial/tournament')\n",
    "    parser.add_argument('--crossover_method',       type=str, default='none',       help='usage: --crossover_method none/default/ensemble')\n",
    "    parser.add_argument('--mutation_type',          type=str, default='normal',     help='usage: --mutation_type normal/stochastic_decaying')\n",
    "    parser.add_argument('--enemy_sets',             type=str, default='1,2,3,4,5,6,7,8',   help='usage: --enemy_sets 1,2,3,4,5,6,7,8/12,13/1')\n",
    "\"\"\"\n",
    "\n",
    "argument_dict = {\n",
    "    \"randomini\": [\"yes\", \"no\"],\n",
    "    \"multi_ini\": [True, False],\n",
    "    \"normalization_method\": [\"default\", \"domain_specific\", \"around_0\"],\n",
    "    \"fitness_method\": [\"default\", \"balanced\", \"rank\"],\n",
    "    \"pick_parent_method\": [\"tournament\", \"greedy\", \"multinomial\"],\n",
    "    \"survivor_method\": [\"multinomial\", \"greedy\", \"tournament\"],\n",
    "    \"crossover_method\": [\"none\", \"default\", \"ensemble\"],\n",
    "    \"mutation_type\": [\"normal\", \"stochastic_decaying\"],\n",
    "}\n",
    "arg_defaults = dict(\n",
    "    randomini=\"no\",\n",
    "    multi_ini=False,\n",
    "    normalization_method=\"default\",\n",
    "    fitness_method=\"rank\",\n",
    "    pick_parent_method=\"multinomial\",\n",
    "    survivor_method=\"multinomial\",\n",
    "    crossover_method=\"none\",\n",
    "    mutation_type=\"normal\",\n",
    ")\n",
    "\n",
    "def dos2unix(filepath):\n",
    "    content = ''\n",
    "    outsize = 0\n",
    "    with open(filepath, 'rb') as infile:\n",
    "        content = infile.read()\n",
    "    with open(filepath, 'wb') as output:\n",
    "        for line in content.splitlines():\n",
    "            outsize += len(line) + 1\n",
    "            output.write(line + b'\\n')\n",
    "\n",
    "def save_job(name, job):\n",
    "    with open(f\"../jobs/{name}.job\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(job)\n",
    "\n",
    "    # Use dos2unix to convert the file to UNIX line endings\n",
    "    dos2unix(f\"../jobs/{name}.job\")\n",
    "\n",
    "# Make one job for default configuration\n",
    "config_str = \"\"\n",
    "job_name = \"default\"\n",
    "job = job_template.format(job_name=job_name, config_str=config_str, n_tasks=n_tasks)\n",
    "save_job(job_name, job)\n",
    "\n",
    "for arg, values in argument_dict.items():\n",
    "    for value in values:\n",
    "        if value == arg_defaults[arg]:\n",
    "            continue\n",
    "        config_str = f\"--{arg} {value}\"\n",
    "        job_name = f\"{arg}_{value}\"\n",
    "        job = job_template.format(job_name=job_name, config_str=config_str, n_tasks=n_tasks)\n",
    "        save_job(job_name, job)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

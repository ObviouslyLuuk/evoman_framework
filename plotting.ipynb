{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show used config values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import json\n",
    "from helpers import RESULTS_DIR\n",
    "\n",
    "# Show possible values for the config files\n",
    "config_values = defaultdict(set)\n",
    "folders = [f for f in os.listdir(RESULTS_DIR) if os.path.isdir(os.path.join(RESULTS_DIR, f))]\n",
    "for folder in folders:\n",
    "    with open(os.path.join(RESULTS_DIR, folder, 'config.json'), 'r') as f:\n",
    "        config = json.load(f)\n",
    "    for key, value in config.items():\n",
    "        config_values[key].add(str(value))\n",
    "\n",
    "# Drop experiment name, best, mean, std\n",
    "ignore = ['experiment_name']\n",
    "for fitness_method in ['default', 'balanced', 'defensive']:\n",
    "    ignore.extend([f'best_{fitness_method}', f'mean_{fitness_method}', f'std_{fitness_method}', f'Q5_{fitness_method}', f'Q95_{fitness_method}'])\n",
    "for key in ignore:\n",
    "    config_values.pop(key, None)\n",
    "display(config_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count runs per config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from helpers import RESULTS_DIR\n",
    "\n",
    "ignore = ['experiment_name']\n",
    "for fitness_method in ['default', 'balanced', 'defensive']:\n",
    "    ignore.extend([f'best_{fitness_method}', f'mean_{fitness_method}', f'std_{fitness_method}', f'Q5_{fitness_method}', f'Q95_{fitness_method}'])\n",
    "\n",
    "# Count number of runs per unique config\n",
    "runs_per_config = defaultdict(int)\n",
    "folders = [f for f in os.listdir(RESULTS_DIR) if os.path.isdir(os.path.join(RESULTS_DIR, f))]\n",
    "for folder in folders:\n",
    "    with open(os.path.join(RESULTS_DIR, folder, 'config.json'), 'r') as f:\n",
    "        config = json.load(f)\n",
    "    for key in ignore:\n",
    "        config.pop(key, None)\n",
    "    if config['gen'] < config['gens']-1:\n",
    "        print(f'Incomplete run: {folder}. {config[\"gen\"]} out of {config[\"gens\"]} generations.')\n",
    "        # Delete folder and contents\n",
    "        shutil.rmtree(os.path.join(RESULTS_DIR, folder))\n",
    "        continue\n",
    "    runs_per_config[str(config)] += 1\n",
    "\n",
    "# Show number of runs per unique config\n",
    "for config, runs in sorted(runs_per_config.items(), key=lambda x: x[0], reverse=True):\n",
    "    print(f'{runs} runs for config {config}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File to show plots for the evolution runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting import create_plot\n",
    "from helpers import find_folders, RESULTS_DIR\n",
    "\n",
    "default_config = { # First experiment with 10 runs\n",
    "    \"randomini\": \"no\",\n",
    "    \"multi_ini\": False,\n",
    "    \"n_hidden_neurons\": 10,\n",
    "    \"pop_size\": 100,\n",
    "    \"mutation_rate\": 0.2,\n",
    "    \"normalization_method\": \"default\",\n",
    "    \"fitness_method\": \"default\",\n",
    "    \"pick_parent_method\": \"tournament\",\n",
    "    \"survivor_method\": \"multinomial\",\n",
    "    \"crossover_method\": \"none\",\n",
    "    \"mutation_type\": \"normal\",\n",
    "    \"domain_upper\": 1,\n",
    "    \"domain_lower\": -1,\n",
    "}\n",
    "\n",
    "default_config = { # Second experiment with 30 runs\n",
    "    \"randomini\": \"no\",\n",
    "    \"multi_ini\": False,\n",
    "    \"n_hidden_neurons\": 10,\n",
    "    \"pop_size\": 100,\n",
    "    \"mutation_rate\": 0.2,\n",
    "    \"normalization_method\": \"default\",\n",
    "    \"fitness_method\": \"rank\",\n",
    "    \"pick_parent_method\": \"multinomial\",\n",
    "    \"survivor_method\": \"multinomial\",\n",
    "    \"crossover_method\": \"none\",\n",
    "    \"mutation_type\": \"normal\",\n",
    "    \"domain_upper\": 1,\n",
    "    \"domain_lower\": -1,\n",
    "}\n",
    "\n",
    "# variable = {\"fitness_method\": [\"default\", \"balanced\"]}  \t        # seems pretty much the same\n",
    "# variable = {\"fitness_method\": [\"default\", \"rank\"]}  \t            # pretty much the same\n",
    "# variable = {\"normalization_method\": [\"default\", \"domain_specific\"]} # seems consistently slightly worse (puzzling)\n",
    "# variable = {\"normalization_method\": [\"default\", \"around_0\"]}        # mean is similar, best is sometimes better, sometimes worse, \n",
    "# variable = {\"pick_parent_method\": [\"tournament\", \"greedy\"]}         # way better mean obviously, inconsistent best\n",
    "# variable = {\"pick_parent_method\": [\"tournament\", \"multinomial\"]}    # multinomial seems consistently better\n",
    "# variable = {\"survivor_method\": [\"multinomial\", \"greedy\"]}           # way better mean obviously, inconsistent best\n",
    "# variable = {\"survivor_method\": [\"multinomial\", \"tournament\"]}           # tournament seems consistently worse\n",
    "# variable = {\"crossover_method\": [\"none\", \"default\"]}                # consistently worse mean, similar best\n",
    "# variable = {\"crossover_method\": [\"none\", \"ensemble\"]}               # consistently worse mean, inconsistent best\n",
    "# variable = {\"randomini\": [\"no\", \"yes\"]}                           # just luck based\n",
    "# variable = {\"multi_ini\": [False, True]}                           # obviously worse scores but better for multi ini eval\n",
    "variable = {\"mutation_type\": [\"normal\", \"stochastic_decaying\"]}   # better mean, maybe slightly better best\n",
    "\n",
    "for enemies in [[1], [2], [3], [4], [5], [6], [7], [8]]:\n",
    "    print(f\"Enemies: {enemies}\")\n",
    "    config = default_config.copy()\n",
    "    config.update({\"enemies\": enemies})\n",
    "\n",
    "    folders_list = []\n",
    "    for value in list(variable.values())[0]:\n",
    "        config.update({list(variable.keys())[0]: value})\n",
    "\n",
    "        folders_list.append(find_folders(config))\n",
    "\n",
    "    create_plot(variable, *folders_list, figsize=(5,3), results_dir=RESULTS_DIR, fitness_method='default')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplots\n",
    "\n",
    "number of wins/defeats isn't great as a metric for a boxplot because it only ranges between 0 and 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots\n",
    "from plotting import create_boxplot\n",
    "from helpers import find_folders, RESULTS_DIR\n",
    "\n",
    "default_config = {\n",
    "    \"randomini\": \"no\",\n",
    "    \"multi_ini\": False,\n",
    "    \"n_hidden_neurons\": 10,\n",
    "    \"pop_size\": 100,\n",
    "    \"mutation_rate\": 0.2,\n",
    "    \"normalization_method\": \"default\",\n",
    "    \"fitness_method\": \"default\",\n",
    "    \"pick_parent_method\": \"tournament\",\n",
    "    \"survivor_method\": \"multinomial\",\n",
    "    \"crossover_method\": \"none\",\n",
    "    \"mutation_type\": \"normal\",\n",
    "    \"domain_upper\": 1,\n",
    "    \"domain_lower\": -1,\n",
    "}\n",
    "default_config = {\n",
    "    \"randomini\": \"no\",\n",
    "    \"multi_ini\": False,\n",
    "    \"n_hidden_neurons\": 10,\n",
    "    \"pop_size\": 100,\n",
    "    \"mutation_rate\": 0.2,\n",
    "    \"normalization_method\": \"default\",\n",
    "    \"fitness_method\": \"rank\",\n",
    "    \"pick_parent_method\": \"multinomial\",\n",
    "    \"survivor_method\": \"multinomial\",\n",
    "    \"crossover_method\": \"none\",\n",
    "    \"mutation_type\": \"normal\",\n",
    "    \"domain_upper\": 1,\n",
    "    \"domain_lower\": -1,\n",
    "}\n",
    "# variable = {\"fitness_method\": [\"default\", \"balanced\"]} # not much difference\n",
    "# variable = {\"normalization_method\": [\"default\", \"domain_specific\"]} # not much difference\n",
    "# variable = {\"pick_parent_method\": [\"tournament\", \"multinomial\"]}\n",
    "# variable = {\"multi_ini\": [False, True]} # obviously much better scores for multi ini eval\n",
    "variable = {\"mutation_type\": [\"normal\", \"stochastic_decaying\"]} # sometimes slightly better, sometimes slightly worse\n",
    "# variable = {\"crossover_method\": [\"none\", \"ensemble\"]} # sometimes slightly better, sometimes slightly worse\n",
    "\n",
    "# Same as above but with boxplots\n",
    "for enemies in [[1], [2], [3], [4], [5], [6], [7], [8]]:\n",
    "    print(f\"Enemies: {enemies}\")\n",
    "    config = default_config.copy()\n",
    "    config.update({\"enemies\": enemies})\n",
    "\n",
    "    folders_list = []\n",
    "    for value in list(variable.values())[0]:\n",
    "        config.update({list(variable.keys())[0]: value})\n",
    "    \n",
    "        folders_list.append(find_folders(config))\n",
    "\n",
    "    create_boxplot(variable, *folders_list, figsize=(5,3), results_dir=RESULTS_DIR, randomini_eval=False, multi_ini_eval=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardest enemies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make boxplot for each enemy based on the best fitness in each run\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from helpers import find_folders, RESULTS_DIR\n",
    "\n",
    "def create_enemy_boxplot(config={}, randomini_eval=False, multi_ini_eval=False, figsize=(5,3), results_dir=RESULTS_DIR, save_png=False, metric='gain'):\n",
    "\n",
    "    add_str = \"\"\n",
    "    if randomini_eval:\n",
    "        add_str = \"_randomini\"\n",
    "    elif multi_ini_eval:\n",
    "        add_str = \"_multi-ini\"\n",
    "\n",
    "    data = []\n",
    "    shortest_folders_len = 1e6\n",
    "    for enemy in range(1,9):\n",
    "        config.update({\"enemies\": [enemy]})\n",
    "        folders = find_folders(config)\n",
    "        shortest_folders_len = min(shortest_folders_len, len(folders))\n",
    "\n",
    "        if not folders:\n",
    "            print(f'No folders found for enemy: {enemy}')\n",
    "            return\n",
    "\n",
    "\n",
    "        runs = []\n",
    "        for folder in folders:\n",
    "            # Create empty df with columns for [gain, fitness, fitness_balanced, n_wins]\n",
    "            df = pd.DataFrame(columns=['gain', 'fitness', 'fitness_balanced', 'wins'])\n",
    "\n",
    "            # Read results from eval_best.json\n",
    "            with open(f'{results_dir}/{folder}/eval_best{add_str}.json', 'r') as f:\n",
    "                saved = json.load(f)\n",
    "            df = pd.DataFrame(saved[\"results\"])\n",
    "            # Turn wins list into number of wins if wins is a list type\n",
    "            if type(df['wins'][0]) == list:\n",
    "                df['wins'] = df['wins'].apply(lambda x: sum(x))\n",
    "\n",
    "            # Average over the 5 evals, keep dims\n",
    "            df = df.mean(axis=0)\n",
    "            df = df.to_frame().transpose()\n",
    "            runs.append(df)\n",
    "        runs = pd.concat(runs, axis=0)\n",
    "\n",
    "        data.append(runs[metric])\n",
    "    print(f'Shortest folder list: {shortest_folders_len}')\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    # Plot boxplot(s)\n",
    "    plt.boxplot(data)\n",
    "    plt.xticks(range(1,9), range(1,9))\n",
    "    plt.title(f'{metric.capitalize()} boxplot')\n",
    "\n",
    "    plt.xlabel('Enemy')\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    if save_png:\n",
    "        if not os.path.exists(f'plots/{str(variable)}'):\n",
    "            os.makedirs(f'plots/{str(variable)}')\n",
    "        plt.savefig(f'plots/{str(variable)}/{metric}_boxplot.png')\n",
    "    plt.show()\n",
    "\n",
    "print('Evaluated on all initial enemy positions')\n",
    "create_enemy_boxplot(config={\n",
    "        \"randomini\": \"no\",\n",
    "        \"multi_ini\": False,\n",
    "    },\n",
    "    randomini_eval=False, multi_ini_eval=True, figsize=(5,3), results_dir=RESULTS_DIR, save_png=False, metric='gain')\n",
    "\n",
    "print('Evaluated on only default enemy position')\n",
    "create_enemy_boxplot(config={\n",
    "        \"randomini\": \"no\",\n",
    "        \"multi_ini\": False,\n",
    "    },\n",
    "    randomini_eval=False, multi_ini_eval=False, figsize=(5,3), results_dir=RESULTS_DIR, save_png=False, metric='gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete folders without config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from helpers import RESULTS_DIR\n",
    "\n",
    "# Get all folders\n",
    "folders = [f for f in os.listdir(RESULTS_DIR) if os.path.isdir(os.path.join(RESULTS_DIR, f))]\n",
    "for folder in folders:\n",
    "    # Check if config.json exists\n",
    "    if not os.path.exists(os.path.join(RESULTS_DIR, folder, 'config.json')):\n",
    "        print(f'No config.json in folder: {folder}, deleting folder')\n",
    "        for file in os.listdir(os.path.join(RESULTS_DIR, folder)):\n",
    "            os.remove(os.path.join(RESULTS_DIR, folder, file))\n",
    "        os.rmdir(os.path.join(RESULTS_DIR, folder))\n",
    "        continue\n",
    "    # else:\n",
    "    #     with open(os.path.join(RESULTS_DIR, folder, 'config.json'), 'r') as f:\n",
    "    #         config = json.load(f)\n",
    "    #     if \"best_log\" not in config:\n",
    "    #         print(f'No best_log in config.json in folder: {folder}, deleting folder')\n",
    "    #         # Delete folder and contents\n",
    "    #         for file in os.listdir(os.path.join(RESULTS_DIR, folder)):\n",
    "    #             os.remove(os.path.join(RESULTS_DIR, folder, file))\n",
    "    #         os.rmdir(os.path.join(RESULTS_DIR, folder))\n",
    "    #         continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update all configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from helpers import RESULTS_DIR\n",
    "\n",
    "# Add variable to all config.json files\n",
    "variable = \"mutation_type\"\n",
    "default_value = \"normal\"\n",
    "\n",
    "folders = [f for f in os.listdir(RESULTS_DIR) if os.path.isdir(os.path.join(RESULTS_DIR, f))]\n",
    "for folder in folders:\n",
    "    with open(os.path.join(RESULTS_DIR, folder, 'config.json'), 'r') as f:\n",
    "        config = json.load(f)\n",
    "    if variable not in config:\n",
    "        config.update({variable: default_value})\n",
    "    with open(os.path.join(RESULTS_DIR, folder, 'config.json'), 'w') as f:\n",
    "        json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Enemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make matplotlib plots interactive\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting import create_plot\n",
    "from helpers import find_folders, RESULTS_DIR\n",
    "\n",
    "default_config = { # Second experiment with 30 runs\n",
    "    \"randomini\": \"no\",\n",
    "    \"multi_ini\": False,\n",
    "    \"n_hidden_neurons\": 10,\n",
    "    \"pop_size\": 100,\n",
    "    \"mutation_rate\": 0.2,\n",
    "    \"normalization_method\": \"default\",\n",
    "    \"fitness_method\": \"rank\",\n",
    "    \"pick_parent_method\": \"multinomial\",\n",
    "    \"survivor_method\": \"multinomial\",\n",
    "    \"crossover_method\": \"none\",\n",
    "    \"mutation_type\": \"stochastic_decaying\",\n",
    "    \"domain_upper\": 1,\n",
    "    \"domain_lower\": -1,\n",
    "}\n",
    "\n",
    "\n",
    "variable = {\"mutation_type\": [\"normal\", \"stochastic_decaying\"]}   # better mean, maybe slightly better best\n",
    "\n",
    "for enemies in [[1,2,3,4,5,6,7,8],[3,4,6,7]]:\n",
    "    print(f\"Enemies: {enemies}\")\n",
    "    config = default_config.copy()\n",
    "    config.update({\"enemies\": enemies})\n",
    "\n",
    "    folders_list = []\n",
    "    for value in list(variable.values())[0]:\n",
    "        config.update({list(variable.keys())[0]: value})\n",
    "\n",
    "        folders_list.append(find_folders(config))\n",
    "\n",
    "    create_plot(variable, *folders_list, figsize=(5,3), results_dir=RESULTS_DIR, fitness_method='default', plot_separate_lines=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
